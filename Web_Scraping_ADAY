library(rvest)
library(dplyr)

link <- "https://www.thisisaday.com/products/something-borrowed-shirt-lake?pr_prod_strat=use_description&pr_rec_id=961e1e62f&pr_rec_pid=7105767768201&pr_ref_pid=4371689341065&pr_seq=uniform"
page = read_html(link)

reviews <- page %>% html_nodes(".yotpo-question-field-description , .content-review") %>% html_text()

reviews <- page %>% html_elements("#MainContent p") %>% html_text()

#clean data
text <- Corpus(VectorSource(reviews))
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removeWords, stopwords("english"))
text <- tm_map(text, removePunctuation)
text <- tm_map(text, stripWhitespace)


#build a table with the words and their frequency
dtm <- TermDocumentMatrix(text)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(frequency=v)
d <- data.frame(word=names(v), frequency=v)
head(d, 20)

#Find frequent terms
findFreqTerms(dtm, lowfreq = 10)

#Examine frequent terms and their assosiation
findAssocs(dtm, terms = "silk", corlimit = 0.3)

#plot the most frequest words
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
         col ="lightgreen", main = "Most frequent words on page",
         ylad = "Word frequencies")
         
         
#generate world cloud  -- library(wordcloud)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
          max.words = 100, random.order = FALSE, rot.per = 0.40,
          colors = brewer.pal(8, "Dark2"))
